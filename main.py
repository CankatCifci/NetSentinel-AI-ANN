import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import subprocess
import re

# Veri setini yÃ¼kle
df = pd.read_csv("Darknet.CSV", on_bad_lines='skip')

# Gereksiz sÃ¼tunlarÄ± kaldÄ±r
drop_columns = ['Flow ID', 'Src IP', 'Dst IP', 'Timestamp']
df = df.drop(columns=drop_columns, errors='ignore')

# Eksik verileri temizle
df = df.replace([np.inf, -np.inf], np.nan)  # Sonsuz deÄŸerleri kaldÄ±r
df = df.dropna()

# Hedef deÄŸiÅŸkeni belirle
y = df['Label']  # veya 'Label.1'
X = df.drop(columns=['Label', 'Label.1'], errors='ignore')

# Kategorik verileri sayÄ±sallaÅŸtÄ±r (One-Hot Encoding)
X = pd.get_dummies(X)

# Hedef deÄŸiÅŸkeni encode et
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)  # SÄ±nÄ±f isimlerini sayÄ±ya Ã§evir (0, 1, 2, 3)

# Veriyi Ã¶lÃ§eklendirme
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Veriyi eÄŸitim ve test setlerine ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Veriyi PyTorch tensÃ¶rlerine Ã§evir
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)


# Yapay Sinir AÄŸÄ± Modeli TanÄ±mla
class ANN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(ANN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x


# Model parametreleri
input_size = X_train.shape[1]
hidden_size = 128
output_size = len(np.unique(y))

# Modeli oluÅŸtur
model = ANN(input_size, hidden_size, output_size)

# KayÄ±p fonksiyonu ve optimizasyon yÃ¶ntemi
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Model eÄŸitimi
epochs = 50
batch_size = 64
for epoch in range(epochs):
    for i in range(0, len(X_train_tensor), batch_size):
        X_batch = X_train_tensor[i:i + batch_size]
        y_batch = y_train_tensor[i:i + batch_size]

        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}")

# Test seti ile model deÄŸerlendirme
with torch.no_grad():
    y_pred_tensor = model(X_test_tensor)
    y_pred = torch.argmax(y_pred_tensor, axis=1).numpy()

# DoÄŸruluk oranÄ± ve sÄ±nÄ±flandÄ±rma raporu
accuracy = accuracy_score(y_test, y_pred)
print(f"Model DoÄŸruluk OranÄ±: {accuracy:.4f}")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix hesaplama
cm = confusion_matrix(y_test, y_pred)
print("\nğŸ§® Confusion Matrix:")
print(cm)

# Detection Rate (DoÄŸruluk OranÄ±) hesaplama
TP = cm[1, 1]
FN = cm[1, 0]
Detection_Rate = TP / (TP + FN)
print(f"Detection Rate (DoÄŸruluk OranÄ±): {Detection_Rate:.4f}")

# False Alarm Rate (YanlÄ±ÅŸ Alarm OranÄ±) hesaplama
FP = cm[0, 1]
TN = cm[0, 0]
False_Alarm_Rate = FP / (FP + TN)
print(f"False Alarm Rate (YanlÄ±ÅŸ Alarm OranÄ±): {False_Alarm_Rate:.4f}")

# Tshark komutunu Ã§alÄ±ÅŸtÄ±rmak iÃ§in subprocess kullanÄ±yoruz
tshark_path = "C:\\Program Files\\Wireshark\\tshark.exe"
interface = 'Wi-Fi'  # Ya da 'Ethernet'

# Tshark komutunu Ã§alÄ±ÅŸtÄ±rÄ±yoruz
tshark_command = [tshark_path, "-i", interface, "-c", "10"]  # Burada "-c 10" ile 10 paket yakalÄ±yoruz


# Tshark Ã§Ä±ktÄ±sÄ±nÄ± iÅŸle
def process_tshark_output(output):
    """
    Tshark Ã§Ä±ktÄ±sÄ±nÄ± iÅŸle ve modelin anlayacaÄŸÄ± formata dÃ¶nÃ¼ÅŸtÃ¼r.
    Bu fonksiyon, tshark Ã§Ä±ktÄ±sÄ±ndan gerekli aÄŸ trafiÄŸi verilerini Ã§Ä±karÄ±r
    ve bunlarÄ± modelin tahmin yapabileceÄŸi sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    processed_data = []

    for line in output.splitlines():
        # Zaman damgasÄ± (ilk sÃ¼tun)
        time_match = re.match(r"^\s*(\d+\.\d+)\s", line)
        if time_match:
            timestamp = float(time_match.group(1))
        else:
            continue

        # Kaynak ve hedef IP'ler (IP adresi arayÄ±ÅŸÄ±)
        ip_match = re.search(r"(\d+\.\d+\.\d+\.\d+)\sâ†’\s(\d+\.\d+\.\d+\.\d+)", line)
        if ip_match:
            src_ip = ip_match.group(1)
            dst_ip = ip_match.group(2)
        else:
            src_ip = dst_ip = None

        # Protokol tÃ¼rÃ¼ (TLS, TCP, DNS, vs.)
        protocol_match = re.search(r"\s([A-Za-z0-9]+)\s", line)
        if protocol_match:
            protocol = protocol_match.group(1)
        else:
            protocol = None

        # Port numaralarÄ± (Kaynak ve hedef portlarÄ±)
        port_match = re.search(r"(\d+)\sâ†’\s(\d+)", line)
        if port_match:
            src_port = int(port_match.group(1))
            dst_port = int(port_match.group(2))
        else:
            src_port = dst_port = None

        # Paket uzunluÄŸu (Len=xxx)
        length_match = re.search(r"Len=(\d+)", line)
        if length_match:
            length = int(length_match.group(1))
        else:
            length = None

        # Bayraklar (ACK, SYN, FIN vb.)
        flags = None
        if "[ACK]" in line:
            flags = "ACK"
        elif "[SYN]" in line:
            flags = "SYN"
        elif "[FIN]" in line:
            flags = "FIN"

        # Ã‡Ä±karÄ±lan veriyi sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rme
        processed_data.append([
            timestamp,  # Zaman damgasÄ±
            src_ip,  # Kaynak IP
            dst_ip,  # Hedef IP
            protocol,  # Protokol
            src_port,  # Kaynak port
            dst_port,  # Hedef port
            length,  # Paket uzunluÄŸu
            flags  # Bayraklar
        ])

    processed_data = np.array(processed_data)
    return processed_data


# GerÃ§ek zamanlÄ± izleme sÄ±rasÄ±nda tshark Ã§Ä±ktÄ±sÄ±nÄ± iÅŸle
try:
    while True:
        result = subprocess.run(tshark_command, capture_output=True, text=True, check=True, encoding='utf-8')
        print(result.stdout)

        # Tshark Ã§Ä±ktÄ±sÄ±nÄ± iÅŸle
        processed_data = process_tshark_output(result.stdout)

        # Model ile tahmin yap
        if processed_data.size > 0:  # EÄŸer iÅŸlenmiÅŸ veri varsa
            processed_tensor = torch.tensor(processed_data, dtype=torch.float32)
            with torch.no_grad():
                model.eval()
                output = model(processed_tensor)
                predicted_class = torch.argmax(output, axis=1).item()

            # Sonucu yorumla
            if predicted_class == 0:  # Ã–rneÄŸin, 0 'gÃ¼venli' kategorisini temsil ediyor
                print("GÃ¼venli")
            else:
                print("Anormal: GÃ¼venli DeÄŸil")

except subprocess.CalledProcessError as e:
    print(f"Tshark komutunu Ã§alÄ±ÅŸtÄ±rÄ±rken hata oluÅŸtu: {e}")
except UnicodeDecodeError as e:
    print("Hata: Tshark Ã§Ä±ktÄ±sÄ± unicode hatasÄ± veriyor. Kodlama hatasÄ± Ã§Ã¶zÃ¼mÃ¼ gerekiyor.")
    result = subprocess.run(tshark_command, capture_output=True, text=True, check=True, encoding='latin-1')
    print(result.stdout)
